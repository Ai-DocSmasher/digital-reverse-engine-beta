import numpy as npimport librosadef true_reverse(audio: np.ndarray, sample_rate: int, **kwargs):    return audio[::-1]def _hann_window(length: int):    return np.hanning(length).astype(np.float32)# ---------- GRAIN REVERSE (unchanged except stereo-safe window) ----------def grain_reverse(    audio: np.ndarray,    sample_rate: int,    grain_size_ms: float = 60.0,    overlap: float = 0.5,    **kwargs):    grain_size = int(sample_rate * grain_size_ms / 1000.0)    grain_size = max(grain_size, 128)    hop = int(grain_size * (1.0 - overlap))    hop = max(hop, 1)    window = _hann_window(grain_size)    if audio.ndim > 1:        window = window[:, None]    out = np.zeros_like(audio, dtype=np.float32)    norm = np.zeros_like(audio, dtype=np.float32)    n = len(audio)    pos = 0    while pos < n:        end = min(pos + grain_size, n)        grain = audio[pos:end]        if len(grain) < grain_size:            pad = grain_size - len(grain)            if audio.ndim == 1:                grain = np.pad(grain, (0, pad))            else:                grain = np.pad(grain, ((0, pad), (0, 0)))        grain_rev = grain[::-1] * window        out[pos:pos + grain_size] += grain_rev[: n - pos]        norm[pos:pos + grain_size] += window[: n - pos]        pos += hop    norm[norm == 0] = 1.0    out /= norm    return out.astype(np.float32)# ---------- SHARED HELPERS FOR STRUCTURAL MODES ----------def _mono_for_analysis(audio: np.ndarray) -> np.ndarray:    if audio.ndim > 1:        return audio.mean(axis=1)    return audiodef _pad_or_trim_to_length(out: np.ndarray, target_len: int) -> np.ndarray:    if len(out) > target_len:        return out[:target_len]    if len(out) < target_len:        if out.ndim == 1:            pad_width = (0, target_len - len(out))        else:            pad_width = ((0, target_len - len(out)), (0, 0))        out = np.pad(out, pad_width)    return out# ---------- 1) TEMPO-GRID STRUCTURAL REVERSE (core) ----------def structural_reverse_tempo_grid(    audio: np.ndarray,    sample_rate: int,    subdivision: float = 0.25,  # 1/4 beat by default):    """    Tempo-grid structural reverse:    - Detect tempo    - Build a deterministic beat grid    - Slice at fixed subdivisions of the beat    - Reverse ORDER of segments, keep audio forward inside    """    mono = _mono_for_analysis(audio)    tempo, beat_frames = librosa.beat.beat_track(y=mono, sr=sample_rate)    if tempo <= 0 or len(beat_frames) < 2:        # Fallback: simple fixed-size structural reverse        return structural_reverse_fixed(audio, sample_rate)    beat_times = librosa.frames_to_time(beat_frames, sr=sample_rate)    beat_duration = np.median(np.diff(beat_times))  # seconds per beat    if not np.isfinite(beat_duration) or beat_duration <= 0:        return structural_reverse_fixed(audio, sample_rate)    step = beat_duration * subdivision  # seconds per grid step    step_samples = int(step * sample_rate)    step_samples = max(step_samples, 128)    grid = np.arange(0, len(audio), step_samples, dtype=int)    if grid[-1] != len(audio):        grid = np.append(grid, len(audio))    segments = []    for start, end in zip(grid[:-1], grid[1:]):        if start >= len(audio):            break        end = min(end, len(audio))        segments.append(audio[start:end])    if not segments:        return audio.astype(np.float32)    segments = segments[::-1]    out = np.concatenate(segments, axis=0)    out = _pad_or_trim_to_length(out, len(audio))    return out.astype(np.float32)def structural_reverse_fixed(    audio: np.ndarray,    sample_rate: int,    segment_ms: float = 80.0,):    """    Fallback structural reverse with fixed-length segments.    """    seg_len = int(sample_rate * segment_ms / 1000.0)    seg_len = max(seg_len, 128)    segments = []    n = len(audio)    pos = 0    while pos < n:        end = min(pos + seg_len, n)        seg = audio[pos:end]        segments.append(seg)        pos += seg_len    if not segments:        return audio.astype(np.float32)    segments = segments[::-1]    out = np.concatenate(segments, axis=0)    out = _pad_or_trim_to_length(out, len(audio))    return out.astype(np.float32)# ---------- 2) HQ_REVERSE: TEMPO-GRID + ONSET SNAPPING ----------def hq_reverse(    audio: np.ndarray,    sample_rate: int,    subdivision: float = 0.25,    onset_snap_ms: float = 30.0,    **kwargs):    """    HQ reverse:    - Tempo-grid structural reverse    - Each grid point optionally snapped to nearest onset    """    mono = _mono_for_analysis(audio)    tempo, beat_frames = librosa.beat.beat_track(y=mono, sr=sample_rate)    if tempo <= 0 or len(beat_frames) < 2:        return structural_reverse_tempo_grid(audio, sample_rate, subdivision=subdivision)    beat_times = librosa.frames_to_time(beat_frames, sr=sample_rate)    beat_duration = np.median(np.diff(beat_times))    if not np.isfinite(beat_duration) or beat_duration <= 0:        return structural_reverse_tempo_grid(audio, sample_rate, subdivision=subdivision)    step = beat_duration * subdivision    step_samples = int(step * sample_rate)    step_samples = max(step_samples, 128)    # Build raw grid    grid = np.arange(0, len(audio), step_samples, dtype=int)    if grid[-1] != len(audio):        grid = np.append(grid, len(audio))    # Onset snapping    onsets = librosa.onset.onset_detect(y=mono, sr=sample_rate, units="samples")    if len(onsets) > 0:        snapped = []        max_offset = int(onset_snap_ms * sample_rate / 1000.0)        for g in grid:            diffs = np.abs(onsets - g)            idx = np.argmin(diffs)            if diffs[idx] <= max_offset:                snapped.append(int(onsets[idx]))            else:                snapped.append(int(g))        grid = np.array(sorted(set(snapped + [0, len(audio)])), dtype=int)    segments = []    for start, end in zip(grid[:-1], grid[1:]):        if start >= len(audio):            break        end = min(end, len(audio))        segments.append(audio[start:end])    if not segments:        return audio.astype(np.float32)    segments = segments[::-1]    out = np.concatenate(segments, axis=0)    out = _pad_or_trim_to_length(out, len(audio))    return out.astype(np.float32)# ---------- 3) TRANSIENTAWARE: TATUM-LIKE SUBDIVISIONS ----------def transientaware_reverse(    audio: np.ndarray,    sample_rate: int,    tatum_subdivision: int = 4,  # 4 tatums per beat    **kwargs):    """    Tatum-like structural reverse:    - Use tempo to define beat    - Subdivide beat into tatums    - Slice at tatums, reverse ORDER only    """    mono = _mono_for_analysis(audio)    tempo, beat_frames = librosa.beat.beat_track(y=mono, sr=sample_rate)    if tempo <= 0 or len(beat_frames) < 2:        # Fallback to HQ tempo-grid        return hq_reverse(audio, sample_rate, subdivision=1.0 / tatum_subdivision)    beat_times = librosa.frames_to_time(beat_frames, sr=sample_rate)    beat_duration = np.median(np.diff(beat_times))    if not np.isfinite(beat_duration) or beat_duration <= 0:        return hq_reverse(audio, sample_rate, subdivision=1.0 / tatum_subdivision)    tatum_duration = beat_duration / tatum_subdivision    tatum_samples = int(tatum_duration * sample_rate)    tatum_samples = max(tatum_samples, 64)    grid = np.arange(0, len(audio), tatum_samples, dtype=int)    if grid[-1] != len(audio):        grid = np.append(grid, len(audio))    segments = []    for start, end in zip(grid[:-1], grid[1:]):        if start >= len(audio):            break        end = min(end, len(audio))        segments.append(audio[start:end])    if not segments:        return audio.astype(np.float32)    segments = segments[::-1]    out = np.concatenate(segments, axis=0)    out = _pad_or_trim_to_length(out, len(audio))    return out.astype(np.float32)# ---------- 4) DJ MODE: 1/8 BEAT SLICING ----------def dj_reverse(    audio: np.ndarray,    sample_rate: int,    **kwargs):    """    DJ mode:    - Aggressive 1/8-beat structural reverse    - Very choppy, rhythmic, performance-style    """    return structural_reverse_tempo_grid(audio, sample_rate, subdivision=0.125)# ---------- 5) STUDIO MODE: BAR-LEVEL STRUCTURAL REVERSE ----------def studio_reverse(    audio: np.ndarray,    sample_rate: int,    beats_per_bar: int = 4,    **kwargs):    """    Studio mode:    - Bar-level structural reverse    - Reverse ORDER of bars, keep bars forward inside    """    mono = _mono_for_analysis(audio)    tempo, beat_frames = librosa.beat.beat_track(y=mono, sr=sample_rate)    if tempo <= 0 or len(beat_frames) < beats_per_bar + 1:        # Fallback: tempo-grid with full-beat segments        return structural_reverse_tempo_grid(audio, sample_rate, subdivision=1.0)    beat_samples = librosa.frames_to_samples(beat_frames)    bar_boundaries = []    for i in range(0, len(beat_samples), beats_per_bar):        bar_boundaries.append(beat_samples[i])    bar_boundaries = np.array(sorted(set(bar_boundaries + [0, len(audio)])), dtype=int)    segments = []    for start, end in zip(bar_boundaries[:-1], bar_boundaries[1:]):        if start >= len(audio):            break        end = min(end, len(audio))        segments.append(audio[start:end])    if not segments:        return audio.astype(np.float32)    segments = segments[::-1]    out = np.concatenate(segments, axis=0)    out = _pad_or_trim_to_length(out, len(audio))    return out.astype(np.float32)